<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> GenAI with LLMs (3) Instruction fine-tuning | Wenwen Kong </title> <meta name="author" content="Wenwen Kong"> <meta name="description" content="Course summary of Generative AI with Large Language Models. Part Three."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://wenwenkong.github.io/blog/2025/gen-ai-llm-3/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Wenwen</span> Kong </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/research/">Research </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Notes </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">GenAI with LLMs (3) Instruction fine-tuning</h1> <p class="post-meta"> Created in June 21, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> llm</a>   ·   <a href="/blog/category/course-summary"> <i class="fa-solid fa-tag fa-sm"></i> course-summary</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>This post covers instruction fine-tuning from the <strong>Generative AI With LLMs</strong> course offered by DeepLearning.AI.</p> <h2 id="llm-fine-tuning-at-a-high-level">LLM fine-tuning at a high level</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/genai_llm_3/1_finetuning_highlevel-480.webp 480w,/assets/img/posts/genai_llm_3/1_finetuning_highlevel-800.webp 800w,/assets/img/posts/genai_llm_3/1_finetuning_highlevel-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/posts/genai_llm_3/1_finetuning_highlevel.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <b>Figure 1.</b> LLM fine-tuning at a high level. Source: course lecture. </div> <h4 id="why-we-need-llm-fine-tuning">Why we need LLM fine-tuning</h4> <p>Recall In-context learning: zero-shot, one-shot, and few-shot inference. See <a href="https://wenwenkong.com/blog/2025/gen-ai-llm-1/#prompt-engineering" rel="external nofollow noopener" target="_blank">this note</a> for more details.</p> <p>We need LLM fine-tuning because in-context learning has several drawbacks:</p> <ul> <li>For smaller models, the in-context learning doesn’t always work, even when 5 or 6 examples are included.</li> <li>Any examples you include in your prompt take up valuable space in the context window, reducing the amount of room you have to include other useful information.</li> </ul> <h4 id="what-is-llm-fine-tuning">What is LLM fine-tuning</h4> <p>Fine-tuning is a <b>supervised learning</b> process, where you use a dataset of labeled examples to update the weights of the LLM.</p> <p><b>Instruction fine-tuning</b> trains the model using examples demonstrating how it should respond to a specific instruction. The labeled examples are <b>prompt-completion pairs</b>; the fine-tuning process extends the training of the model to improve its ability to generate good completions for a specific task.</p> <p>Each example in the prompt-completion pairs datasets begins with <b>instructions</b>. For example, if you want to fine-tune your model to improve its summarization ability, you’d build up a dataset of examples that begin with instruction “summarize the following text” or a similar phrase; if you are improving the model’s translation skills, your examples would include instructions like “translate this sentence”. These examples allow the model to learn to generate responses following given responses.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/genai_llm_3/2_finetuning_highlevel-480.webp 480w,/assets/img/posts/genai_llm_3/2_finetuning_highlevel-800.webp 800w,/assets/img/posts/genai_llm_3/2_finetuning_highlevel-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/posts/genai_llm_3/2_finetuning_highlevel.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <b>Figure 2.</b> Using prompts to fine-tune LLMs with instruction. Source: course lecture. </div> <p><b>Instruction fine-tuning</b>, where all of the model’s weights are updated, is known as <b>full fine-tuning</b>. The process results in a new version of the model with updated weights. Note that just like pre-training, full fine-tuning requires enough memory and compute budget to store and process all the gradients, optimizers, and other components that are being updated during training.</p> <h2 id="llm-fine-tuning-process">LLM fine-tuning process</h2> <p>First step of instruction fine-tuning is to prepare your training data. There is much publicly available data that has been used to train earlier generations of LLMs, but not all of them are formatted as instructions. Developers have assembled <a href="https://github.com/bigscience-workshop/promptsource/tree/main/promptsource/templates" rel="external nofollow noopener" target="_blank">prompt template libraries</a> that can be used to take existing dataset. For example,turn the large dataset of Amazon product review into instruction prompt datasets for fine-tuning (see <b>Figure 3</b>, <a href="https://github.com/bigscience-workshop/promptsource/blob/main/promptsource/templates/amazon_polarity/templates.yaml" rel="external nofollow noopener" target="_blank">source</a>). In each case, you pass in the original review, here called <code class="language-plaintext highlighter-rouge">review_body</code>, to the template, where it gets inserted into the text that starts with an instruction. The result is a prompt that now contains both an instruction and the example from the dataset.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/genai_llm_3/3_prompt_instruction_template-480.webp 480w,/assets/img/posts/genai_llm_3/3_prompt_instruction_template-800.webp 800w,/assets/img/posts/genai_llm_3/3_prompt_instruction_template-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/posts/genai_llm_3/3_prompt_instruction_template.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <b>Figure 3.</b> Sample prompt instruction templates. Source: course lecture. </div> <p>Once the instruction dataset is ready, we divide the dataset into <code class="language-plaintext highlighter-rouge">training</code>, <code class="language-plaintext highlighter-rouge">validation</code>, <code class="language-plaintext highlighter-rouge">test</code> split.</p> <p>During fine-tuning, we select prompts from the training set and pass them to the LLM which then generates completions. Next, we compare LLM completion with the response specified in the training data.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/genai_llm_3/4_finetuning_process-480.webp 480w,/assets/img/posts/genai_llm_3/4_finetuning_process-800.webp 800w,/assets/img/posts/genai_llm_3/4_finetuning_process-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/posts/genai_llm_3/4_finetuning_process.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <b>Figure 4.</b> LLM fine-tuning process. Source: course lecture. </div> <p>Recall that the output of an LLM is a probability distribution across tokens. So we can compare the distribution of the completion and that of the training label, and use the standard <a href="https://en.wikipedia.org/wiki/Cross-entropy" rel="external nofollow noopener" target="_blank"><b>cross entropy function</b></a> to calculate <b>loss</b> between the two token distributions. Then use the calculated loss to update model weights in standard <b>backpropagation</b>. Do this for many batches of prompt completion pairs and over several epochs, update the weights so that the model’s performance on the task improves. Then get the <b>validation_accuracy</b> using the holdout validation set, and get the <b>test_accuracy</b> once you apply the model to the test set.</p> <h2 id="single-task-vs-multi-task">Single task vs. Multi-task</h2> <h3 id="single-task-fine-tuning">Single task fine-tuning</h3> <p>Good results can be achieved with relatively few examples (often 500-1000 examples) for single task fine-tuning. However, fine-tuning on a single task can lead to <b>catastrophic forgetting</b>, i.e. fine-tuning significantly improves performance of the model on a specific task but degrades performance on other tasks.</p> <p>How to avoid catastrophic forgetting?</p> <ul> <li>First of all, you might not have to if you only care about the task you fine-tuned for</li> <li>Fine-tune on multiple tasks at the same time</li> <li>Consider Parameter Efficient Fine-tuning (PEFT)</li> </ul> <h3 id="multi-task-fine-tuning">Multi-task fine-tuning</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/genai_llm_3/5_multitask_finetuning-480.webp 480w,/assets/img/posts/genai_llm_3/5_multitask_finetuning-800.webp 800w,/assets/img/posts/genai_llm_3/5_multitask_finetuning-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/posts/genai_llm_3/5_multitask_finetuning.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <b>Figure 5.</b> Multi-task fine-tuning. Source: course lecture. </div> <p>Over many epochs of training, the calculated losses across examples are used to update the weights of the model, resulting in an instruction fine-tuned model that learned how to be good at many different tasks simultaneously.</p> <p>Drawback to multi-task fine-tuning: requires a lot of data. However, it can be very worthwhile and worth the effort to assemble this data. The resulting models are often very capable and suitable for use in situations where good performance at many tasks is desirable.</p> <h2 id="instruction-fine-tuning-with-flan">Instruction fine-tuning with FLAN</h2> <p>FLAN == <b>F</b>ine-tuned <b>LA</b>nguage <b>N</b>et. FLAN models refer to a specific set of instructions used to perform instruction fine-tuning. FLAN-T5 (fine-tuned version of pre-trained T5 model) is a great, general purpose, instruct model.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/genai_llm_3/6_FLAN-480.webp 480w,/assets/img/posts/genai_llm_3/6_FLAN-800.webp 800w,/assets/img/posts/genai_llm_3/6_FLAN-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/posts/genai_llm_3/6_FLAN.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <b>Figure 6.</b> Datasets and task categories employed in FLAN fine-tuning, <a href="https://arxiv.org/abs/2210.11416" target="_blank" rel="external nofollow noopener">source</a>. </div> <h2 id="llm-evaluation">LLM evaluation</h2> <h4 id="metrics-rouge">Metrics: ROUGE</h4> <p><b>ROUGE</b> is used for text summarization and text generation tasks. Figures in below demonstrate usage of <b>ROUGE-1</b>, <b>ROUGE-2</b>, <b>ROUGE-L</b>, and <b>ROUGE clipping</b>.</p> <p><b>ROUGE-1</b> measures the overlap of <b>unigrams (single words)</b> between the generated and reference texts.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/genai_llm_3/7_ROUGE_1-480.webp 480w,/assets/img/posts/genai_llm_3/7_ROUGE_1-800.webp 800w,/assets/img/posts/genai_llm_3/7_ROUGE_1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/posts/genai_llm_3/7_ROUGE_1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <b>Figure 7.</b> ROUGE-1. Source: course lecture. </div> <p><b>ROUGE-2</b> measures the overlap of <b>bigrams (two-word sequences)</b> between the generated and reference texts.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/genai_llm_3/8_ROUGE_2-480.webp 480w,/assets/img/posts/genai_llm_3/8_ROUGE_2-800.webp 800w,/assets/img/posts/genai_llm_3/8_ROUGE_2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/posts/genai_llm_3/8_ROUGE_2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <b>Figure 8.</b> ROUGE-2. Source: course lecture. </div> <p><b>ROUGE-L</b> measures the <b>longest common subsequences (LCS)</b> between the generated and reference texts, capturing setence-level fluency and structure.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/genai_llm_3/9_ROUGE_L-480.webp 480w,/assets/img/posts/genai_llm_3/9_ROUGE_L-800.webp 800w,/assets/img/posts/genai_llm_3/9_ROUGE_L-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/posts/genai_llm_3/9_ROUGE_L.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <b>Figure 9.</b> ROUGE-L. Source: course lecture. </div> <p><b>ROUGE clipping</b> limits the count of overlapping n-grams to the maximum number that appears in the reference, preventing the generated text from getting extra credit for repeated words.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/genai_llm_3/10_ROUGE_clipping-480.webp 480w,/assets/img/posts/genai_llm_3/10_ROUGE_clipping-800.webp 800w,/assets/img/posts/genai_llm_3/10_ROUGE_clipping-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/posts/genai_llm_3/10_ROUGE_clipping.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <b>Figure 10.</b> ROUGE clipping. Source: course lecture. </div> <h4 id="metrics-bleu-score">Metrics: BLEU SCORE</h4> <p><b>BLEU SCORE</b> is used for text translation. Below is the core BLEU formula, from <a href="https://aclanthology.org/P02-1040.pdf" rel="external nofollow noopener" target="_blank">Papineni et al. 2002</a>.</p> \[\text{BLEU} = \text{BP} \cdot \exp\left( \sum_{n=1}^{N} w_n \log p_n \right)\] <ul> <li> <strong>BLEU</strong>: The final BLEU score (0 to 1), evaluating how closely the generated text matches the reference.</li> <li> <strong>BP</strong>: <em>Brevity Penalty</em> — penalizes candidates that are shorter than the reference.</li> <li> <strong>\(\exp\)</strong>: Exponential function, used to combine the log-precisions into a geometric mean.</li> <li> <strong>\(w_n\)</strong>: Weight for each n-gram order (e.g., 0.25 when using up to 4-grams).</li> <li> <strong>\(p_n\)</strong>: <em>Modified precision</em> for n-grams of size \(n\), with clipping to avoid over-counting.</li> <li> <strong>\(N\)</strong>: Maximum n-gram order (usually 4 in practice).</li> </ul> <h4 id="benchmarks">Benchmarks</h4> <p>Selecting an evaluating dataset is vital to an accurate evaluation of model performance. Example evaluation benchmarks include <a href="https://gluebenchmark.com/" rel="external nofollow noopener" target="_blank">GLUE</a>, <a href="https://super.gluebenchmark.com/" rel="external nofollow noopener" target="_blank">SuperGLUE</a>, <a href="https://paperswithcode.com/dataset/mmlu" rel="external nofollow noopener" target="_blank">MMLU (Massive Multitask Language Understanding)</a>, <a href="https://crfm.stanford.edu/helm/" rel="external nofollow noopener" target="_blank">HELM</a>, <a href="https://github.com/google/BIG-bench" rel="external nofollow noopener" target="_blank">Big-bench</a>, etc.</p> <h2 id="references">References</h2> <ul> <li> <a href="https://arxiv.org/pdf/2210.11416.pdf" rel="external nofollow noopener" target="_blank">Scaling Instruction-Finetuned Language Models</a> <ul> <li>Scaling fine-tuning with a focus on task, model size and chain-of-thought data.</li> </ul> </li> <li> <a href="https://ai.googleblog.com/2021/10/introducing-flan-more-generalizable.html" rel="external nofollow noopener" target="_blank">Introducing FLAN: More generalizable Language Models with Instruction Fine-Tuning</a> <ul> <li>This blog (and article) explores instruction fine-tuning, which aims to make language models better at performing NLP tasks with zero-shot inference.</li> </ul> </li> <li> <a href="https://crfm.stanford.edu/helm/latest/" rel="external nofollow noopener" target="_blank">HELM - Holistic Evaluation of Language Models</a> <ul> <li>HELM is a living benchmark to evaluate Language Models more transparently.</li> </ul> </li> <li> <a href="https://openreview.net/pdf?id=rJ4km2R5t7" rel="external nofollow noopener" target="_blank">General Language Understanding Evaluation (GLUE) benchmark</a> <ul> <li>This paper introduces GLUE, a benchmark for evaluating models on diverse natural language understanding (NLU) tasks and emphasizing the importance of improved general NLU systems.</li> </ul> </li> <li> <a href="https://super.gluebenchmark.com/" rel="external nofollow noopener" target="_blank">SuperGLUE</a> <ul> <li>This paper introduces SuperGLUE, a benchmark designed to evaluate the performance of various NLP models on a range of challenging language understanding tasks.</li> </ul> </li> <li> <a href="https://aclanthology.org/W04-1013.pdf" rel="external nofollow noopener" target="_blank">ROUGE: A Package for Automatic Evaluation of Summaries</a> <ul> <li>This paper introduces and evaluates four different measures (ROUGE-N, ROUGE-L, ROUGE-W, and ROUGE-S) in the ROUGE summarization evaluation package, which assess the quality of summaries by comparing them to ideal human-generated summaries.</li> </ul> </li> <li><a href="https://aclanthology.org/P02-1040.pdf" rel="external nofollow noopener" target="_blank">BLEU: a Method for Automatic Evaluation of Machine Translation</a></li> <li> <a href="https://arxiv.org/pdf/2009.03300.pdf" rel="external nofollow noopener" target="_blank">Measuring Massive Multitask Language Understanding (MMLU)</a> <ul> <li>This paper presents a new test to measure multitask accuracy in text models, highlighting the need for substantial improvements in achieving expert-level accuracy and addressing lopsided performance and low accuracy on socially important subjects.</li> </ul> </li> <li> <a href="https://arxiv.org/pdf/2206.04615.pdf" rel="external nofollow noopener" target="_blank">BigBench-Hard - Beyond the Imitation Game: Quantifying and Extrapolating the Capabilities of Language Models</a> <ul> <li>The paper introduces BIG-bench, a benchmark for evaluating language models on challenging tasks, providing insights on scale, calibration, and social bias.</li> </ul> </li> </ul> </div> </article> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Wenwen Kong. Powered by <a href="http://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: June 29, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-research",title:"Research",description:"",section:"Navigation",handler:()=>{window.location.href="/research/"}},{id:"nav-notes",title:"Notes",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-teaching",title:"Teaching",description:"Courses that I've taught and students that I've mentored.",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"post-genai-with-llms-4-parameter-efficient-fine-tuning",title:"GenAI with LLMs (4) Parameter-efficient fine-tuning",description:"Course summary of Generative AI with Large Language Models. Part Four.",section:"Posts",handler:()=>{window.location.href="/blog/2025/gen-ai-llm-4/"}},{id:"post-genai-with-llms-3-instruction-fine-tuning",title:"GenAI with LLMs (3) Instruction fine-tuning",description:"Course summary of Generative AI with Large Language Models. Part Three.",section:"Posts",handler:()=>{window.location.href="/blog/2025/gen-ai-llm-3/"}},{id:"post-genai-with-llms-2-pre-training",title:"GenAI with LLMs (2) Pre-training",description:"Course summary of Generative AI with Large Language Models. Part Two.",section:"Posts",handler:()=>{window.location.href="/blog/2025/gen-ai-llm-2/"}},{id:"post-genai-with-llms-1-fundamentals",title:"GenAI with LLMs (1) Fundamentals",description:"Course summary of Generative AI with Large Language Models. Part One.",section:"Posts",handler:()=>{window.location.href="/blog/2025/gen-ai-llm-1/"}},{id:"post-predicting-u-s-soybean-yield-with-climate-data",title:"Predicting U.S. Soybean Yield with Climate Data",description:"An end-to-end machine learning project on U.S. soybean yield prediction",section:"Posts",handler:()=>{window.location.href="/blog/2025/us-soybean-prediction/"}},{id:"post-statistical-learning-notes-outline",title:"Statistical Learning Notes Outline",description:"Outline of notes about statistical learning.",section:"Posts",handler:()=>{window.location.href="/blog/2023/sl-notes-outline/"}},{id:"post-statistics-and-climate-journal-club",title:"Statistics and Climate Journal Club",description:"Archived topics discussed in the Statistics and Climate Journal Club at UCLA.",section:"Posts",handler:()=>{window.location.href="/blog/2022/stats-climate-journalclub/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=UDAPrT8AAAAJ","_blank")}},{id:"socials-publons",title:"Publons",section:"Socials",handler:()=>{window.open("https://publons.com/a/Y-8516-2019/","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/wenwenkong","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/wenwenkong","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>